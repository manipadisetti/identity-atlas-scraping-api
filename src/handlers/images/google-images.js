// src/handlers/images/google-images.js
const { createPage, navigateWithRetry, autoScroll } = require('../../utils/browser');
const { withCache } = require('../../utils/cache');
const { logScraping } = require('../../utils/logger');

async function scrapeGoogleImages(query) {
  const startTime = Date.now();
  
  return withCache('google-images', query, async () => {
    const page = await createPage();
    
    try {
      console.log(`[GOOGLE_IMAGES] Searching for: ${query}`);

      const searchUrl = `https://www.google.com/search?q=${encodeURIComponent(query)}&tbm=isch`;
      await navigateWithRetry(page, searchUrl);
      
      await page.waitForSelector('img', { timeout: 10000 });
      await autoScroll(page, 3);

      const images = await page.evaluate(() => {
        const results = [];
        const imgElements = document.querySelectorAll('img[data-src], img[src]');
        
        imgElements.forEach((img, index) => {
          if (index >= 30) return;
          
          const src = img.getAttribute('data-src') || img.getAttribute('src');
          if (src && !src.includes('logo') && src.startsWith('http')) {
            results.push({
              url: src,
              alt: img.getAttribute('alt') || '',
              width: img.naturalWidth || 0,
              height: img.naturalHeight || 0
            });
          }
        });
        
        return results;
      });

      await page.close();

      const duration = Date.now() - startTime;
      logScraping('google-images', query, duration, true, images.length);

      console.log(`[GOOGLE_IMAGES] âœ“ Found ${images.length} images in ${duration}ms`);

      return {
        source: 'google-images',
        query: query,
        scrapedAt: new Date().toISOString(),
        data: {
          images,
          totalResults: images.length
        },
        confidence: images.length > 0 ? 80 : 30
      };

    } catch (error) {
      await page.close();
      const duration = Date.now() - startTime;
      logScraping('google-images', query, duration, false);

      console.error(`[GOOGLE_IMAGES] âœ— Error searching:`, error.message);
      throw new Error(`Google Images scraping failed: ${error.message}`);
    }
  }, 86400);
}

module.exports = { scrapeGoogleImages };
```

4. **Commit**

---

## ðŸŽ‰ **YOU'RE DONE WITH ALL THE CODE!**

**Now let's verify your structure!**

Send me a screenshot of your GitHub repo showing the `src/` folder structure so I can verify everything is in place!

Then we'll check Railway and test the API! ðŸš€

---

## ðŸ“‚ **YOUR FINAL STRUCTURE SHOULD BE:**
```
identity-atlas-scraping-api/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Procfile
â”œâ”€â”€ nixpacks.toml
â”œâ”€â”€ package.json
â”œâ”€â”€ README.md
â””â”€â”€ src/
    â”œâ”€â”€ index.js
    â”œâ”€â”€ middleware/
    â”‚   â”œâ”€â”€ auth.js
    â”‚   â””â”€â”€ rateLimit.js
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ browser.js
    â”‚   â”œâ”€â”€ cache.js
    â”‚   â””â”€â”€ logger.js
    â””â”€â”€ handlers/
        â”œâ”€â”€ professional/
        â”‚   â”œâ”€â”€ linkedin.js
        â”‚   â”œâ”€â”€ github.js
        â”‚   â”œâ”€â”€ stackoverflow.js
        â”‚   â””â”€â”€ medium.js
        â”œâ”€â”€ social/
        â”‚   â”œâ”€â”€ twitter.js
        â”‚   â””â”€â”€ reddit.js
        â”œâ”€â”€ content/
        â”‚   â””â”€â”€ youtube.js
        â”œâ”€â”€ news/
        â”‚   â””â”€â”€ google-news.js
        â”œâ”€â”€ business/
        â”‚   â””â”€â”€ abn-lookup.js
        â”œâ”€â”€ academic/
        â”‚   â””â”€â”€ google-scholar.js
        â””â”€â”€ images/
            â””â”€â”€ google-images.js
